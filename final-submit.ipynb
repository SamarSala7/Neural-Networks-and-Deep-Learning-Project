{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"trusted":true},"outputs":[],"source":["                                                                                                    import numpy as np \n","import pandas as pd \n","import cv2\n","import os\n","from random import shuffle\n","from tqdm import tqdm\n","from keras.preprocessing.image import ImageDataGenerator\n","import tensorflow.keras as k\n","import tensorflow as tf\n","import csv\n","import matplotlib.pyplot as plt\n","from tensorflow.keras import layers\n","import seaborn as sns\n","from keras.models import Model\n","from keras.initializers import glorot_uniform\n","from tensorflow.keras.layers import Add, ZeroPadding2D, Activation, BatchNormalization, Conv2D, MaxPool2D, Dropout, Dense, Input, concatenate, GlobalAveragePooling2D, AveragePooling2D, Flatten\n"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","editable":false,"execution":{"iopub.execute_input":"2022-12-27T18:44:02.296737Z","iopub.status.busy":"2022-12-27T18:44:02.296037Z","iopub.status.idle":"2022-12-27T18:44:02.312742Z","shell.execute_reply":"2022-12-27T18:44:02.311852Z","shell.execute_reply.started":"2022-12-27T18:44:02.296700Z"},"trusted":true},"outputs":[],"source":["def create_label(image_name):\n","    \"\"\" Create an one-hot encoded vector from image name \"\"\"\n","    word_label = image_name.split('_')\n","    if word_label[0] == 'Basketball':\n","        return np.array([1,0,0,0,0,0])\n","    elif word_label[0] == 'Football':\n","        return np.array([0,1,0,0,0,0])\n","    elif word_label[0] == 'Rowing':\n","        return np.array([0,0,1,0,0,0])\n","    elif word_label[0] == 'Swimming':\n","        return np.array([0,0,0,1,0,0])\n","    elif word_label[0] == 'Tennis':\n","        return np.array([0,0,0,0,1,0])\n","    elif word_label[0] == 'Yoga':\n","        return np.array([0,0,0,0,0,1])\n","\n","def create_train_data():\n","    training_data = []\n","    for img in tqdm(os.listdir(TRAIN_DIR)):\n","        path = os.path.join(TRAIN_DIR, img)\n","        img_data = cv2.imread(path)\n","        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n","        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n","        norm_img = np.zeros((IMG_SIZE,IMG_SIZE))\n","        img_data = cv2.normalize(img_data,  norm_img, 0, 255, cv2.NORM_MINMAX)\n","        img_data = img_data.astype('float')\n","        training_data.append([np.array(img_data), create_label(img)])\n","    \n","    return training_data\n","\n","def create_test_data():\n","    test_data = []\n","    for img in tqdm(os.listdir(TEST_DIR)):\n","        path = os.path.join(TEST_DIR, img)\n","        img_data = cv2.imread(path)\n","        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n","        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n","        norm_img = np.zeros((IMG_SIZE,IMG_SIZE))\n","        img_data = cv2.normalize(img_data,  norm_img, 0, 255, cv2.NORM_MINMAX)\n","        img_data = img_data.astype('float')\n","        test_data.append([np.array(img_data), create_label(img)])\n","    \n","    \n","    shuffle(test_data)\n","    return test_data\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2022-12-27T18:44:02.317035Z","iopub.status.busy":"2022-12-27T18:44:02.316058Z","iopub.status.idle":"2022-12-27T18:44:30.213727Z","shell.execute_reply":"2022-12-27T18:44:30.212715Z","shell.execute_reply.started":"2022-12-27T18:44:02.316915Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1681/1681 [00:17<00:00, 97.87it/s] \n"]},{"name":"stdout","output_type":"stream","text":["(224, 224, 3)      599\n","(408, 612, 3)      145\n","(180, 320, 3)       50\n","(183, 275, 3)       48\n","(240, 240, 3)       41\n","                  ... \n","(240, 195, 3)        1\n","(612, 457, 3)        1\n","(1500, 2250, 3)      1\n","(258, 195, 3)        1\n","(377, 699, 3)        1\n","Length: 409, dtype: int64\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 688/688 [00:10<00:00, 67.02it/s] "]},{"name":"stdout","output_type":"stream","text":["(408, 612, 3)      200\n","(224, 224, 3)       29\n","(612, 408, 3)       23\n","(183, 275, 3)       22\n","(306, 612, 3)       11\n","                  ... \n","(1135, 2000, 3)      1\n","(1280, 1920, 3)      1\n","(628, 1200, 3)       1\n","(167, 301, 3)        1\n","(858, 1680, 3)       1\n","Length: 279, dtype: int64\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["TRAIN_DIR = '/kaggle/input/nn23-sports-image-classification/Train'\n","TEST_DIR = '/kaggle/input/nn23-sports-image-classification/Test'\n","\n","size_train_data = []\n","for img in tqdm(os.listdir(TRAIN_DIR)):\n","        path = os.path.join(TRAIN_DIR, img)\n","        img_data = plt.imread(path)\n","        size_train_data.append(img_data.shape)\n","\n","print(pd.Series(size_train_data).value_counts())\n","\n","\n","\n","size_test_data = []\n","for img in tqdm(os.listdir(TEST_DIR)):\n","        path = os.path.join(TEST_DIR, img)\n","        img_data = plt.imread(path)\n","        size_test_data.append(img_data.shape)\n","\n","print(pd.Series(size_test_data).value_counts())\n"]},{"cell_type":"code","execution_count":4,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2022-12-27T18:44:30.217093Z","iopub.status.busy":"2022-12-27T18:44:30.216472Z","iopub.status.idle":"2022-12-27T18:44:39.333140Z","shell.execute_reply":"2022-12-27T18:44:39.332217Z","shell.execute_reply.started":"2022-12-27T18:44:30.217055Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1681/1681 [00:09<00:00, 184.91it/s]\n","100%|██████████| 1681/1681 [00:00<00:00, 460734.82it/s]\n"]}],"source":["IMG_SIZE = 224\n","MODEL_NAME = \"[NN'23] Sports Image Classification\"\n","\n","class1_data = [] \n","class2_data = []\n","class3_data = []\n","class4_data = []\n","class5_data = []\n","class6_data = []\n","\n","list_visualize_classes = []\n","\n","train_data = create_train_data()\n","\n","for img in tqdm(train_data):\n","    if img[1][0] == 1:\n","        class1_data.append(img)\n","        list_visualize_classes.append('Basketball')\n","    elif img[1][1] == 1:\n","        class2_data.append(img)\n","        list_visualize_classes.append('Football')\n","    elif img[1][2] == 1:\n","        class3_data.append(img)\n","        list_visualize_classes.append('Rowing')\n","    elif img[1][3] == 1:\n","        class4_data.append(img)\n","        list_visualize_classes.append('Swimming')\n","    elif img[1][4] == 1:\n","        class5_data.append(img)\n","        list_visualize_classes.append('Tennis')\n","    elif img[1][5] == 1:\n","        class6_data.append(img)\n","        list_visualize_classes.append('Yoga')\n","        \n","\n","\n","shuffle(class1_data)    \n","shuffle(class2_data)\n","shuffle(class3_data)\n","shuffle(class4_data)\n","shuffle(class5_data)            \n","shuffle(class6_data)\n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2022-12-27T18:44:39.336031Z","iopub.status.busy":"2022-12-27T18:44:39.335578Z","iopub.status.idle":"2022-12-27T18:44:39.549049Z","shell.execute_reply":"2022-12-27T18:44:39.548063Z","shell.execute_reply.started":"2022-12-27T18:44:39.336002Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n","  FutureWarning\n"]},{"name":"stdout","output_type":"stream","text":["Number of Basketball Images:  196 Image\n","Number of Football Images:    400 Image\n","Number of Rowing Images:      202 Image\n","Number of Swimming Images:    240 Image\n","Number of Tennis Images:      185 Image\n","Number of Yoga Images:        458 Image\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["sns.countplot(list_visualize_classes)\n","\n","print(\"Number of Basketball Images: \", len(class1_data), \"Image\")\n","print(\"Number of Football Images:   \", len(class2_data), \"Image\")\n","print(\"Number of Rowing Images:     \", len(class3_data), \"Image\")\n","print(\"Number of Swimming Images:   \", len(class4_data), \"Image\")\n","print(\"Number of Tennis Images:     \", len(class5_data), \"Image\")\n","print(\"Number of Yoga Images:       \", len(class6_data), \"Image\")\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2022-12-27T18:44:39.551135Z","iopub.status.busy":"2022-12-27T18:44:39.550395Z","iopub.status.idle":"2022-12-27T18:44:40.154791Z","shell.execute_reply":"2022-12-27T18:44:40.153372Z","shell.execute_reply.started":"2022-12-27T18:44:39.551096Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1681, 224, 224, 3)\n","(1681, 6)\n"]}],"source":["data = class1_data + class2_data + class3_data + class4_data + class5_data + class6_data\n","\n","X_train = np.array([i[0] for i in data]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n","y_train = np.array([i[1] for i in data])\n","\n","\n","print(X_train.shape)\n","print(y_train.shape)"]},{"cell_type":"code","execution_count":7,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2022-12-27T18:44:40.156827Z","iopub.status.busy":"2022-12-27T18:44:40.156438Z","iopub.status.idle":"2022-12-27T18:44:40.917115Z","shell.execute_reply":"2022-12-27T18:44:40.916098Z","shell.execute_reply.started":"2022-12-27T18:44:40.156770Z"},"trusted":true},"outputs":[],"source":["datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\n","datagen.fit(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2022-12-27T19:17:53.521684Z","iopub.status.busy":"2022-12-27T19:17:53.521270Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","53/53 [==============================] - ETA: 0s - loss: 2.4609 - accuracy: 0.7222"]}],"source":["def identity_block(X, f, filters, stage, block):\n","   \n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","    F1, F2, F3 = filters\n","\n","    X_shortcut = X\n","   \n","    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2a')(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b')(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n","\n","    X = Add()([X, X_shortcut])# SKIP Connection\n","    X = Activation('relu')(X)\n","\n","    return X\n","\n","\n","\n","\n","def convolutional_block(X, f, filters, stage, block, s=2):\n","   \n","    conv_name_base = 'res' + str(stage) + block + '_branch'\n","    bn_name_base = 'bn' + str(stage) + block + '_branch'\n","\n","    F1, F2, F3 = filters\n","\n","    X_shortcut = X\n","\n","    X = Conv2D(filters=F1, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '2a')(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2a')(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F2, kernel_size=(f, f), strides=(1, 1), padding='same', name=conv_name_base + '2b', )(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2b')(X)\n","    X = Activation('relu')(X)\n","\n","    X = Conv2D(filters=F3, kernel_size=(1, 1), strides=(1, 1), padding='valid', name=conv_name_base + '2c')(X)\n","    X = BatchNormalization(axis=3, name=bn_name_base + '2c')(X)\n","\n","    X_shortcut = Conv2D(filters=F3, kernel_size=(1, 1), strides=(s, s), padding='valid', name=conv_name_base + '1')(X_shortcut)\n","    X_shortcut = BatchNormalization(axis=3, name=bn_name_base + '1')(X_shortcut)\n","\n","    X = Add()([X, X_shortcut])\n","    X = Activation('relu')(X)\n","\n","    return X\n","\n","\n","def ResNet50(input_shape=(224, 224, 3)):\n","\n","    X_input = Input(input_shape)\n","\n","    X = ZeroPadding2D((3, 3))(X_input)\n","\n","    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1')(X)\n","    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n","    X = Activation('relu')(X)\n","    X = MaxPool2D((3, 3), strides=(2, 2))(X)\n","\n","    X = convolutional_block(X, f=3, filters=[64, 64, 256], stage=2, block='a', s=1)\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n","    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n","\n","\n","    X = convolutional_block(X, f=3, filters=[128, 128, 512], stage=3, block='a', s=2)\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n","    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n","\n","    X = convolutional_block(X, f=3, filters=[256, 256, 1024], stage=4, block='a', s=2)\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n","    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n","\n","    X = X = convolutional_block(X, f=3, filters=[512, 512, 2048], stage=5, block='a', s=2)\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n","    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n","\n","    X = AveragePooling2D(pool_size=(2, 2), padding='same')(X)\n","    \n","  \n","\n","    \n","    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n","    \n","    \n","\n","    return model\n","\n","\n","\n","\n","\n","Res_50_model = ResNet50(input_shape=(224, 224, 3))\n","\n","\n","headModel = Res_50_model.output\n","headModel = Flatten()(headModel)\n","headModel=Dense(256, activation='relu', name='fc1')(headModel)\n","headModel=Dense(128, activation='relu', name='fc2')(headModel)\n","headModel = Dense(6 ,activation='softmax', name='fc3')(headModel)\n","model = Model(inputs=Res_50_model.input, outputs=headModel)\n","\n","\n","Res_50_model.load_weights(\"/kaggle/input/resnet1/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\")\n","\n","for layer in Res_50_model.layers:\n","    layer.trainable = False\n","\n","check_point = k.callbacks.ModelCheckpoint(filepath=\"resnet_50.h5\", monitor=\"val_acc\", mode=\"max\", save_best_only=True,)\n","model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n","\n","history = model.fit(datagen.flow(X_train, y_train), validation_data=(X_train,y_train), \n","                    epochs=10, batch_size=64, callbacks=[check_point])\n","model.save('model.h5')\n"]},{"cell_type":"code","execution_count":16,"metadata":{"editable":false,"execution":{"iopub.execute_input":"2022-12-27T19:05:45.997669Z","iopub.status.busy":"2022-12-27T19:05:45.996678Z","iopub.status.idle":"2022-12-27T19:06:30.999621Z","shell.execute_reply":"2022-12-27T19:06:30.998097Z","shell.execute_reply.started":"2022-12-27T19:05:45.997628Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 688/688 [00:42<00:00, 16.21it/s]\n"]}],"source":["saved = tf.keras.models.load_model('/kaggle/input/modelh5')\n","testing_data=[]\n","for img in tqdm(os.listdir(TEST_DIR)):\n","        path = os.path.join(TEST_DIR, img)\n","        img_data = cv2.imread(path)\n","        img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n","        test_img = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n","        test_img = test_img.reshape(IMG_SIZE, IMG_SIZE, 3)\n","        norm_img = np.zeros((IMG_SIZE,IMG_SIZE))\n","        img_data = cv2.normalize(test_img,  norm_img, 0, 255, cv2.NORM_MINMAX)\n","        img_data = np.expand_dims(img_data, axis=0)\n","        prediction = saved.predict(img_data)[0]\n","        max_value = max(prediction)\n","        index = np.where(prediction == max_value)\n","        testing_data.append([img, index[0][0]])\n","        \n","with open('sport.csv','w+') as file:\n"," myfile = csv.writer(file)\n"," myfile.writerow(['image_name', 'label'])\n"," for i in range(len(testing_data)):\n","    myfile.writerow(testing_data[i])"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8 (tags/v3.8.8:024d805, Feb 19 2021, 13:18:16) [MSC v.1928 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"2aafef98629c34f0dd50f1e4184df7f72eab5dbaa033abb9f1368f15b17f95fe"}}},"nbformat":4,"nbformat_minor":4}
